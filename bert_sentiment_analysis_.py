# -*- coding: utf-8 -*-
"""BERT sentiment analysis .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qqLwE8zFeE2goJdD28yUB6UiL4W68JUP

**3 Steps**

This is so easy from hugging face we use transformers
1.  In transformers we have two parameter
*   Tokenizer
*   Model

2.  Tokenizer encode our sequences

3.   Models takes encoded data as input and gives output in form of value from 1 to 5

**Install and import dependencies**
"""

from transformers import Pipeline
from bs4 import BeautifulSoup
import pandas as pd
import requests
import re
import tensorflow as tf
import numpy as np
import torch #to use argmax we are using pytorch

from transformers import AutoModelForSequenceClassification,AutoTokenizer

"""**Initializing model**

"""

modelname="nlptown/bert-base-multilingual-uncased-sentiment"

tokenizer=AutoTokenizer.from_pretrained(modelname)
model=AutoModelForSequenceClassification.from_pretrained(modelname)

tokens=tokenizer.encode('i is not good',return_tensors='pt')

token=tokenizer.decode(tokens[0]) ##,skip_special_tokens=True to remove tokens
token

res=model(tokens)
res

res.logits[0]

int(torch.argmax(res.logits[0]))+1

"""Re-writing the same code in a function for reuse"""

def sentiment_text(sequence):
  tokens=tokenizer.encode(sequence,return_tensors='pt')
  sent=model(tokens)
  val=torch.argmax(sent.logits[0])
  return int(val)+1

"""**Collecting food review data from yelp.com website**"""

req=requests.get("https://www.yelp.com/biz/taco-bell-san-francisco-12")
soup=BeautifulSoup(req.text,'html.parser')
ret=re.compile('.*comment.*')
results=soup.find_all('p',{'class':ret})
reviews=[result.text for result in results]

reviews[0]

df=pd.DataFrame(reviews,columns=['Review'])

df.head()

df['Ratings']=df['Review'].apply(sentiment_text)

df

"""**Writing dataframe to excel file**"""

df.to_csv('Restaurant review.csv',index=False)